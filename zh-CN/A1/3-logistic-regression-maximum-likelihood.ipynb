{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归问题的极大似然解法\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(0xff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本例中，我们使用的数据和感知机那一节所使用的数据相同，如下：\n",
    "\n",
    "![problemset](problemset.png)\n",
    "\n",
    "不过本例中不同的是，我们将该问题视作一个二分类问题，而不是回归问题。\n",
    "\n",
    "对于一个输入$x$，我们定义它属于1类的概率为$\\hat{p}$，计算如下：\n",
    "\n",
    "$$\n",
    "\\hat{p}(x, w) = \\phi( w^T x )\n",
    "$$\n",
    "\n",
    "其中$w$是待确定的参数，$\\phi$是sigmoid函数，使用sigmoid函数的一个原因是，根据$\\hat{p}(x, w)$的定义，有$\\hat{p}(x, w) \\in [0, 1]$，而sigmoid函数能够将输出限制到$(0, 1)$之间。$\\phi(z) = \\frac{1}{1 + e^{-z}}$，其函数图像如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.arange(-10, 10, 0.1)\n",
    "plt.plot(z, 1/(1 + np.exp(-z)))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi(z)$的导数为$\\phi'(z)=\\phi(z)(1-\\phi(z))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了$\\hat{p}(x)$的定义，我们可以定义输入$x$属于0类和1类的概率：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(y=1 | x, w) & = \\hat{p}(x, w) \\\\\n",
    "P(y=0 | x, w) & = 1 - \\hat{p}(x, w)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "上面两个公式可以统一为一个公式：\n",
    "\n",
    "$$\n",
    "p(y | x, w) = \\hat{p}(x, w)^y (1 - \\hat{p}(x, w))^{1-y}\n",
    "$$\n",
    "\n",
    "其中$y$是一个参数，如果我们需要计算$x$属于1类的概率，则将$y$设为$1$，然后按照右边的公式进行计算，同样可以将$y$设为$0$计算属于0类的概率。\n",
    "\n",
    "然后我们可以定义“**根据参数$w$，产生输入$X$的正确分类$Y$的概率**”，此处的$X$和$Y$是指全体数据。比如假设我们找到一个参数$w$，计算出$x1$属于1类的概率为$0.7$，$x2$属于1类的概率为$0.6$，而$x1$的真实分类为1,$x2$的真实分类为0,那么由我们计算出的概率生成$x1$和$x2$的正确分类的概率为$0.7 \\times (1 - 0.6) = 0.28$，这个数值就是likelihood。\n",
    "\n",
    "可以看到，随着我们调整参数$w$，最终生成正确分类的概率也会改变，极大似然算法的目标就是找出参数$w$是的最终的likelihood最大。\n",
    "\n",
    "但是在实际计算中，由于计算likelihood中需要计算很多数值在$0$到$1$范围内的连乘，会导致最终的结果太小，因此一般都会对likelihood取log（因为log函数是单调函数，likelihood最大的参数，在取log之后依然是最大的）。\n",
    "\n",
    "而log函数的底数的选择并不太重要，一般选择以$e$为底，主要是便于求导。\n",
    "\n",
    "到此，我们可以定义参数$w$的log-likelihood：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(w) & = log p(Y | X, w) \\\\\n",
    "     & = log \\prod_{(x, y) \\in samples} p(y | x, w) \\\\\n",
    "     & = \\sum_{(x, y) \\in samples} log p(y | x, w) \\\\\n",
    "     & = \\sum_{(x, y) \\in samples} log( \\hat{p}(x, w)^y (1 - \\hat{p}(x, w))^{1-y} ) \\\\\n",
    "     & = \\sum_{(x, y) \\in samples} y \\times log( \\hat{p}(x, w) ) + (1-y) \\times log( 1 - \\hat{p}(x, w) )\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "我们可以使用梯度下降的算法来求解该问题，$L(w)$的导数为：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial{L(w)}}{\\partial{w}}\n",
    "    & = \\sum_{(x, y) \\in samples} \\left( y \\times \\frac{1}{\\hat{p}(x, w)} - (1-y) \\times \\frac{1}{1 - \\hat{p}(x, w)} \\right) \\times \\frac{\\partial{\\hat{p}(x, w)}}{\\partial{w}} \\\\\n",
    "    & = \\sum_{(x, y) \\in samples} \\left( y \\times \\frac{1}{\\phi( w^T x )} - (1-y) \\times \\frac{1}{1 - \\phi( w^T x )} \\right) \\times \\frac{\\partial{\\phi( w^T x )}}{\\partial{w}} \\\\\n",
    "    & = \\sum_{(x, y) \\in samples} \\left( y \\times \\frac{1}{\\phi( w^T x )} - (1-y) \\times \\frac{1}{1 - \\phi( w^T x )} \\right) \\times \\phi( w^T x )(1 - \\phi( w^T x )) \\times x \\\\\n",
    "    & = \\sum_{(x, y) \\in samples} \\left( y \\times (1 - \\phi( w^T x )) - (1-y) \\times \\phi( w^T x ) \\right) \\times x \\\\\n",
    "    & = \\sum_{(x, y) \\in samples} ( y - y \\times \\phi( w^T x ) - \\phi( w^T x ) + y \\times \\phi( w^T x ) ) \\times x \\\\\n",
    "    & = \\sum_{(x, y) \\in samples} ( y - \\phi( w^T x ) ) \\times x\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "推导过程有点长，但是并不复杂，最后的结果也非常简洁。这里还是要提醒一下，在实际的机器学习中，可以只用关注每个简单运算的求导即可，并不需要求出一个解析解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.transpose(np.array([\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "]))\n",
    "y = np.array([\n",
    "    0, 1, 1, 0\n",
    "])\n",
    "new_x = np.array([\n",
    "    1, 0, 0\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46393652, 0.22303538, 0.32222402])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.rand(3)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57986617, 0.73286276, 0.68700633, 0.63303504])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigmoid(np.dot(w, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 # 学习率\n",
    "steps = 10000 # 迭代数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设定梯度下降相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [0 1 1 0]\n",
      "step = 0, output = [0.57986617 0.73286276 0.68700633 0.63303504]\n",
      "step = 1000, output = [0.166824   0.88722435 0.92022258 0.12015289]\n",
      "step = 2000, output = [0.09144295 0.93878021 0.95869007 0.06235682]\n",
      "step = 3000, output = [0.06205814 0.95857442 0.97239128 0.04165868]\n",
      "step = 4000, output = [0.04673184 0.96884246 0.97932902 0.03117215]\n",
      "step = 5000, output = [0.03739216 0.97508383 0.9835017  0.0248668 ]\n",
      "step = 6000, output = [0.03112653 0.97926518 0.98628206 0.0206672 ]\n",
      "step = 7000, output = [0.02664041 0.98225654 0.98826516 0.01767315]\n",
      "step = 8000, output = [0.02327391 0.98450018 0.98974993 0.01543237]\n",
      "step = 9000, output = [0.02065641 0.98624405 0.99090274 0.01369322]\n"
     ]
    }
   ],
   "source": [
    "print(f'y = {y}')\n",
    "for step in range(steps):\n",
    "    output = sigmoid(np.dot(w, x)) # 计算输出\n",
    "    gradient = (y - output)[:, np.newaxis] * np.transpose(x)\n",
    "    gradient = np.sum(gradient, axis=0) # 计算梯度\n",
    "    \n",
    "    w = w + learning_rate * gradient # 更新\n",
    "    if step % 1000 == 0:\n",
    "        print(f'step = {step}, output = {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，在迭代了这么多次之后，我们的输出与标准输出已经非常接近了。\n",
    "\n",
    "这里需要注意的是，我们的目标是使得log-likelihood最大，因此参数$w$的更新规则是$w = w + learning\\_rate \\times \\frac{\\partial L(w)}{w}$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [ 8.76606251 -0.41760842 -3.96778809], new_x = [1 0 0], new_y = 0.9998440879404841\n"
     ]
    }
   ],
   "source": [
    "new_y = sigmoid(np.dot(new_x, w))\n",
    "\n",
    "print(f'w = {w}, new_x = {new_x}, new_y = {new_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们同样可以使用牛顿迭代法求解使$L(w)$最大的参数$w$，不过比较麻烦的地方在于牛顿迭代法是用来求解零点的，并不是求解最小点或最大点（比如，有一个函数$f(z)$，牛顿迭代能够找到一个$z$使得$f(z)=0$，但是并不能找到f(z)的最大点或者最小点）。\n",
    "\n",
    "因此使用牛顿迭代法找$L(w)$的最大值实际上是寻找参数$w$使得$L'(w)=0$，参数$w$的更新规则是：\n",
    "\n",
    "$$\n",
    "w = w - \\frac{L'(w)}{L''(w)}\n",
    "$$\n",
    "\n",
    "因此此处需要求解$L(w)$的二阶导，由于参数$w$是一个多维向量，参数$w$的更新规则是：\n",
    "\n",
    "$$\n",
    "w = w - H^{-1} \\nabla_w L(w)\n",
    "$$\n",
    "\n",
    "其中$H$是$L(w)$关于$w$的海森矩阵(Hessian matrix, https://en.wikipedia.org/wiki/Hessian_matrix)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
